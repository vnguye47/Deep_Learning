{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task2_Vinguyen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCPX5-HWPY5C"
      },
      "source": [
        "There are some Neural Network architectural choices I will be using to guide my decision in building this model.\n",
        "My first choice of NNDL algorithm will be the Long/Short Term Memory.LSTM networks introduce a memory cell. They can process data with memory gaps.\n",
        "Because we have a large number of relevant data, and we want to find out relevant data from it, then LSTMs is the way to go. Due to the nature of this multiclass multilabel problem: the last layer activation of the NN must be Sigmoid and loss function is binary_crossentropy. I will attempt different optimizers and metric to find the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73_Daw_YNhiL"
      },
      "source": [
        "#Libaries \n",
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc3gp1_WNlrK"
      },
      "source": [
        "#Colab specific code to set up environment and reading in csv file\n",
        "## Code piece to mount my Google Drive\n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "# See the list of files in this local folder \n",
        "!ls -l '/content/drive/My Drive/Colab Notebooks'\n",
        "# Change the working directory to Colab Notebooks\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "\n",
        "# Ensure the files are there by listing\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPBDInDWNw_u"
      },
      "source": [
        "#Reading in the train.csv\n",
        "train= pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv')\n",
        "\n",
        "#Reading in the test.csv\n",
        "test= pd.read_csv('/content/drive/My Drive/Colab Notebooks/test.csv')\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvcksyuUSJMO"
      },
      "source": [
        "**Pre-Processing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRwAzONeOsED"
      },
      "source": [
        "#Labels to be classified\n",
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values\n",
        "list_sentences_train = train[\"comment_text\"]\n",
        "list_sentences_test = test[\"comment_text\"]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PHojz43N_M3"
      },
      "source": [
        "#Tokenization - Breaking down sentences into words or this case tokens \n",
        "#Indexing - We put the words in a dictionary-like structure and give them an index each For eg, {1:\"I\",2:\"love\",3:\"cats\",4:\"and\",5:\"dogs\"}\n",
        "#Index Representation- will represent the sequence of words in the comments in the form of index, and feed this chain of index into our LSTM. For eg, [1,2,3,4,2,5]\n",
        "\n",
        "#limiting the number of features to 10000\n",
        "max_features = 10000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tM3-h1GOxpe",
        "outputId": "cacdbb5f-f20d-4b9d-aa18-9935ac896b9b"
      },
      "source": [
        "list_tokenized_train[:1]\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[688,\n",
              "  75,\n",
              "  1,\n",
              "  126,\n",
              "  130,\n",
              "  177,\n",
              "  29,\n",
              "  672,\n",
              "  4511,\n",
              "  1116,\n",
              "  86,\n",
              "  331,\n",
              "  51,\n",
              "  2278,\n",
              "  50,\n",
              "  6864,\n",
              "  15,\n",
              "  60,\n",
              "  2756,\n",
              "  148,\n",
              "  7,\n",
              "  2937,\n",
              "  34,\n",
              "  117,\n",
              "  1221,\n",
              "  2825,\n",
              "  4,\n",
              "  45,\n",
              "  59,\n",
              "  244,\n",
              "  1,\n",
              "  365,\n",
              "  31,\n",
              "  1,\n",
              "  38,\n",
              "  27,\n",
              "  143,\n",
              "  73,\n",
              "  3462,\n",
              "  89,\n",
              "  3085,\n",
              "  4583,\n",
              "  2273,\n",
              "  985]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAooTr3HO5QD"
      },
      "source": [
        " I will be using padding. I could make shorter sentences as long as the others by filling the shortfall by zeros and also have to trim the longer ones to the same length(maxlen) as the short ones. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdNUXQAzPAiK"
      },
      "source": [
        "#I have set the max length to be 200.\n",
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMVpvB1oPGGR"
      },
      "source": [
        "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRPA5fREPG-P"
      },
      "source": [
        " #maxlen=200 as defined earlier\n",
        " inp = Input(shape=(maxlen, ))\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHRl-DFjPwq4"
      },
      "source": [
        "embed_size = 128\n",
        "#first layer of the model\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "#second layer\n",
        "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
        "#third layer\n",
        "x = GlobalMaxPool1D()(x)\n",
        "#fourth layer\n",
        "x = Dropout(0.1)(x)\n",
        "#fifth layer\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "#sixth layer\n",
        "x = Dropout(0.1)(x)\n",
        "#Last Layer of Activation must be sigmoid\n",
        "x = Dense(6, activation=\"sigmoid\")(x)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_YLxjCsQf1R"
      },
      "source": [
        "#Initial Model with adam as optimizer and accuracy as metric\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "#Loss function is binary_crossentropy\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRVRvo98QlHu",
        "outputId": "a1d3b241-4bab-46c2-ecc5-c663c57d09e4"
      },
      "source": [
        "#Number of training example in a single batch\n",
        "batch_size = 32\n",
        "#Training on two epoch\n",
        "epochs = 2\n",
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 121s 27ms/step - loss: 0.0695 - accuracy: 0.9328 - val_loss: 0.0497 - val_accuracy: 0.9936\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 121s 27ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0489 - val_accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1929395c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5gf6euiSxht"
      },
      "source": [
        "#Model two has SGD as optimizer and not adam\n",
        "model2 = Model(inputs=inp, outputs=x)\n",
        "#Loss function is binary_crossentropy\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OZLyQGjTbZY",
        "outputId": "0fe88506-4bf5-45d0-e16f-622ff68a6c3b"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "model2.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 59s 13ms/step - loss: 0.0405 - accuracy: 0.9931 - val_loss: 0.0480 - val_accuracy: 0.9939\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 59s 13ms/step - loss: 0.0401 - accuracy: 0.9921 - val_loss: 0.0479 - val_accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1ff9df828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhvoUj2_Uf73"
      },
      "source": [
        "#Model three has SGD as optimizer since and AUC as metric\n",
        "model3 = Model(inputs=inp, outputs=x)\n",
        "#Loss function is binary_crossentropy\n",
        "model3.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['AUC'])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rcrRDzDU-Fj",
        "outputId": "55283032-7923-4d24-e09d-0368dce20f51"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "model3.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 64s 14ms/step - loss: 0.0401 - auc: 0.9882 - val_loss: 0.0479 - val_auc: 0.9800\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 63s 14ms/step - loss: 0.0400 - auc: 0.9882 - val_loss: 0.0479 - val_auc: 0.9802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1fe4a1668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uykwy-0wYzE-"
      },
      "source": [
        "#Model foour has adam as optimizer and AUC as metric\n",
        "model4 = Model(inputs=inp, outputs=x)\n",
        "#Loss function is binary_crossentropy\n",
        "model4.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['AUC'])\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOsFoGB_Y4qc",
        "outputId": "2eb2b431-766a-4133-ea39-f2ff6ba71937"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "model4.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 120s 27ms/step - loss: 0.0699 - auc: 0.9592 - val_loss: 0.0499 - val_auc: 0.9809\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 120s 27ms/step - loss: 0.0468 - auc: 0.9822 - val_loss: 0.0478 - val_auc: 0.9815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1fd1b44e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY3L9f70XCIQ"
      },
      "source": [
        "**Model three is the best model with the SGD as the optimizer and AUC as the metric.**\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}